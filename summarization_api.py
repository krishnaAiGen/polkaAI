from langchain_community.llms import Ollamaclass Summarization:    def __init__(self, model):        self.model = model        def get_summary(self, input_text):          llm = Ollama(model=self.model, temperature=1)                  initial_prompt = "Generate me a summary of following text: "        final_prompt = f"{initial_prompt} '{input_text}'"                output = llm.invoke(final_prompt)                        return output                    def summarization(self, input_text):        summarized_text = self.get_summary(input_text)                return summarized_text